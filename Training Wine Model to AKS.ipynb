{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59639e6d-7fd6-4925-b2b4-663f4e54a899",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Deploy Models from Databricks to AKS\n",
    "This example notebook demonstrates how to deploy models trained in Databricks to Azure Kubernetes Compute on Azure Machine Learning. The main goal is to be able to deploy using code only, and in a seamless manner, with only a Databricks notebook and the right configurations.\n",
    "This notebook is the part two of the series [How to deploy model trained on Databricks to Azure ML Endpoint or AKS](https://jnguyends.medium.com/in-depth-guide-deploy-models-from-databricks-to-azure-ml-2023-6d71572eb6f7). \n",
    "\n",
    "**Notebook Cluster Config:** DBR 13.0 ML / Standard DS3_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1829d1cb-a0c0-4749-a05d-5338a967b31b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Configure Databricks to AML\n",
    "**Important:** In order to successfully let Databricks communicate with Azure ML, you will first need to **grant access** to Databricks to write and read from Azure ML. You can find how-to in the first section of the guide here: [Setup Managed Identity roles for Access Permission](https://jnguyends.medium.com/in-depth-guide-deploy-models-from-databricks-to-azure-ml-2023-6d71572eb6f7). \n",
    "\n",
    "When that's done, you can move on to the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5493bba-e850-454d-b4d4-ebfbcbf81d95",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Install Azure Machine Learning Dependencies\n",
    "Now, you can install the following Python packages which contain integration code of AzureML with MLflow, and will help create AKS deployment resources. You can either use `pip install` or [install them directly on your cluster](https://learn.microsoft.com/en-us/azure/databricks/libraries/cluster-libraries#--install-a-library-on-a-cluster):\n",
    "\n",
    "- `azureml-mlflow`\n",
    "- `azure-ai-ml`\n",
    "- `azureml-core`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2a510b7-237f-4a9a-9102-ada3776d0eb0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install azure-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f010d21-6ce1-4c02-82ae-9dcded76e89c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install azureml-mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f68b407-f3d8-4c4c-a45a-ee76b21c9b27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install azureml-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5e083d9-d04a-48f4-b1dd-292e8f7049e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d711f93-05e8-4f4c-85b7-6f85fb2907a9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Connect MLFlow to Azure ML Server\n",
    "After that, configure your resources information to retrieve your Azure ML workspace like in the code snipped below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66cc6469-a6e4-4ec0-a7d5-6dce9c8cf96c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# TODO: Enter details of your Azure Machine Learning workspace\n",
    "subscription_id = \"<Subscription ID of your resource group>\"\n",
    "resource_group = \"<Resource group having your resources>\"\n",
    "workspace_name = \"<Your azure workspace name>\"\n",
    "\n",
    "# Retrieves your Azure ML resources with already set up Managed Identity\n",
    "ml_client = MLClient(credential=DefaultAzureCredential(),\n",
    "                        subscription_id=subscription_id, \n",
    "                        workspace_name=workspace_name,\n",
    "                        resource_group_name=resource_group)\n",
    "\n",
    "# Retrieves MLflow tracking URI of Azure ML workspace\n",
    "aml_tracking_uri = ml_client.workspaces.get(ml_client.workspace_name).mlflow_tracking_uri\n",
    "\n",
    "# Changes MLflow tracking URI to Azure ML server\n",
    "mlflow.set_tracking_uri(aml_tracking_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfc1480f-a74c-4652-9ab6-2f9fe9b2e72f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Train and Log Model to AML\n",
    "Now, we want to train a simple model and register it to Azure ML Model Registry. We are using the wine quality dataset to create a wine quality scoring model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60846d22-8ec8-43a0-94e7-29ea3991711f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Load Wine Quality Dataset\n",
    "The Dataset used in this example is from http://archive.ics.uci.edu/ml/datasets/Wine+Quality. By P.Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7c4cccc-cb5a-4865-99a4-9c5c2e3580b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import mlflow.sklearn\n",
    "\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv\", sep=\";\")\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train, test = train_test_split(data)\n",
    "\n",
    "# The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "train_x = train.drop([\"quality\"], axis=1)\n",
    "test_x = test.drop([\"quality\"], axis=1)\n",
    "train_y = train[[\"quality\"]]\n",
    "test_y = test[[\"quality\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c94308e1-337d-4480-ba1e-2a0364cbfc67",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Train and Track ML Model Experiments\n",
    "To track MLflow experiments on Azure ML, you need to create an MLflow experiment and set the experiment. Else using MLflow will return the exception `BadRequest: Experiment ID must be a GUID.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cad11c1-44f6-4c80-a6e6-e66bf41a3709",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creates and sets the experiment when using MLflow with Azure ML\n",
    "experiment_name = \"wine_quality_aks\"\n",
    "mlflow.set_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02a6001a-54f8-4494-af0a-50c9b502d180",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "After that, we train a model and log the model experiment to MLflow. \n",
    "\n",
    "Notice how we associate a signature to our model. A model signature in MLflow defines the schema of a model’s inputs and outputs. It is not mandatory but it’s good practice to log model with their signature. Azure Machine Learning enforces compliance with it, both in terms of the number of inputs and their types when using online inference endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8204df4-333a-4bcc-9ad4-d3ef0d771cce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "l1_ratio = 0.5\n",
    "artifact_path = \"model\"\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    # Keep the metadata of the run\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # Train your model\n",
    "    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "    lr.fit(train_x, train_y)\n",
    "    predicted_qualities = lr.predict(test_x)\n",
    "    mlflow.log_params({\"alpha\": alpha, \"l1_ratio\": l1_ratio})\n",
    "\n",
    "    # Infer model signature\n",
    "    signature = mlflow.models.infer_signature(model_input=test_x[:10], model_output=predicted_qualities[:10])\n",
    "\n",
    "    # Log the model to the experiment\n",
    "    mlflow.sklearn.log_model(lr, artifact_path, signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb28a1cf-8a3f-4f48-8b3b-909e9656074a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Register the Model on AML Model Registry\n",
    "Once you are satisfied with your model experimentation, you can register your best model version by using `register_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec2ac815-3249-4a24-8926-1eff4a24a9fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "registered_model_name = \"wine_quality\"\n",
    "registered_model = mlflow.register_model(f\"runs:/{run_id}/{artifact_path}\", registered_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be694f19-7c58-4c5f-b190-301f7767cee7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Test Model for Batch Predictions\n",
    "\n",
    "You can load a model version by specifying its name and version number. Below, we load the latest version of our registered model using [mlflow.pyfunc.load_model](https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#mlflow.pyfunc.load_model) and apply it for inference on our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edd4a072-1723-4173-b015-bc461c81fbf7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "model_version = registered_model.version\n",
    "model_version_uri = f\"models:/{registered_model_name}/{model_version}\"\n",
    "model_version = mlflow.pyfunc.load_model(model_version_uri)\n",
    "model_version.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cbe35c8-27d3-4b91-9117-cd38725e3473",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Serve the model with AKS Compute Endpoint\n",
    "When you create an AKSCompute in Azure ML, it is provisioned as a managed service specifically designed for running machine learning workloads. \n",
    "Azure ML abstracts away the underlying infrastructure management, making it easier to deploy and manage machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cb71060-a5da-46cd-a8f4-de29576a4110",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.authentication import MsiAuthentication\n",
    "\n",
    "# Retrieves your Azure ML resources with already set up Managed Identity\n",
    "ws = Workspace(subscription_id=subscription_id,\n",
    "               resource_group=resource_group,\n",
    "               workspace_name=workspace_name,\n",
    "               auth=MsiAuthentication())\n",
    "\n",
    "print(\"Found workspace {} at location {}\".format(ws.name, ws.location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36f78a7a-1a0a-4991-95bc-e12f52f6d035",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Create AKS Compute Endpoint\n",
    "You can either deploy your model endpoint to a new AKS resources, or you can attach the model endpoint to an existing AKS resource. We will demonstrate both way. Let's start with a new AKS resource creation, managed by Azure ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f357a78-fde2-4dac-ac17-c05a1c83d45c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### a. Attach Endpoint to New AKS resource\n",
    "If you want to **use an existing AKS resource, go to step b.**\n",
    "\n",
    "Here, we create our AKSCompute Endpoint which takes about 5 minutes to roll out. The AKSCompute endpoint name `aks_name` has some restriction. It must start with a letter, end with a letter or digit, and be between 2 and 16 characters in length. It can include letters, digits and dashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65229702-40db-4a42-90ef-b1bd3d5d34a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Use the default configuration (can also provide parameters to customize)\n",
    "prov_config = AksCompute.provisioning_configuration(vm_size = \"Standard_DS2_v2\",\n",
    "                                                    agent_count = 3,\n",
    "                                                    location = \"westus\")\n",
    "\n",
    "# Create the cluster\n",
    "aks_endpoint_name = \"wine-endpoint-1\"\n",
    "aks_target = ComputeTarget.create(workspace=ws, \n",
    "                                  name=aks_name, \n",
    "                                  provisioning_configuration=prov_config)\n",
    "\n",
    "aks_target.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0621eb4f-be06-475f-ae52-8033e670d5b0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### b. Attach Endpoint to Existing AKS resource\n",
    "You might need to grant proper permissions for Databricks to attach the AKS resource to Azure ML. \n",
    "\n",
    "You can follow the same steps as we did above to grant Databricks permission to AKS. If you encounter errors, know that there is a minimum pool node size requirements in order to deploy endpoints on an existing AKS resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26651c78-4204-487c-aa55-659815115858",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Fill your AKS resource information\n",
    "existing_aks_name = \"<existing aks resource name>\"\n",
    "subscription_id = \"<azure subscription id>\" \n",
    "resource_group = \"<resource group of aks>\"\n",
    "aks_resource_id = f\"/subscriptions/{subscription_id}/resourcegroups/{resource_group}/providers/Microsoft.ContainerService/managedClusters/{existing_aks_name}\"\n",
    "\n",
    "# Create configuration and attach the AKS pool to an AKSCompute endpoint\n",
    "aks_endpoint_name = \"wine-endpoint-1\"\n",
    "existing_attach_config = AksCompute.attach_configuration(resource_id=aks_resource_id)\n",
    "aks_target = ComputeTarget.attach(ws, aks_endpoint_name, existing_attach_config)\n",
    "\n",
    "aks_target.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92e96fa7-b4d5-40c5-b076-e4793846d051",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Create Model Deployments on Endpoint\n",
    "Finally, we can create our model deployment on the endpoint. Let's create the json configuration file for the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78aaf737-0d23-4492-abc1-9672d83b29df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "deployment_config = {\"computeType\": \"aks\", \"computeTargetName\": aks_endpoint_name}\n",
    "\n",
    "deployment_config_path = \"deployment_config.json\"\n",
    "with open(deployment_config_path, \"w\") as outfile:\n",
    "    outfile.write(json.dumps(deployment_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9902924-161a-4a05-9986-52283d7c200c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We can then deploy our model from Model Registry using the deployment_client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f71c0ba1-6b9b-47b6-8582-2747f0f1e560",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "# set the tracking uri as the deployment client\n",
    "client = get_deploy_client(mlflow.get_tracking_uri())\n",
    "version = registered_model.version\n",
    "\n",
    "# set the deployment config\n",
    "deploy_path = \"deployment_config.json\"\n",
    "test_config = {'deploy-config-file': deploy_path}\n",
    "\n",
    "# define the model path and the name is the service name\n",
    "# the model gets registered automatically and a name is autogenerated using the \"name\" parameter below \n",
    "deployment_name = \"default\"\n",
    "client.create_deployment(model_uri=f\"models:/{registered_model_name}/{version}\",\n",
    "                         config=test_config,\n",
    "                         name=deployment_name)\n",
    "\n",
    "# Fetch the endpoint scoring uri\n",
    "scoring_uri = client.get_endpoint(endpoint=aks_endpoint_name)[\"properties\"][\"scoringUri\"]\n",
    "print(scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14bde7ee-4b11-4ef0-8c52-fd2348d0d77d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The deployment will take about 5 minutes to roll out. After that, you are done and you can test out your served model on AKS! This will also create a AKS cluster in your resource group which you can configure and govern as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4f2099a-5e57-4599-8f86-057797684969",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Test and Query AKS Compute Endpoint with requests\n",
    "Here's how to do a request on the model deployed endpoint you just created.\n",
    "\n",
    "**TODO:** Replace `api_key` with the primary/secondary key or AMLToken for the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02229cdf-63c5-49a1-ad1e-0db3bb418f35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Use it\n",
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "data =  {\n",
    "  \"input_data\": {\n",
    "    \"columns\": [\n",
    "      \"fixed acidity\",\n",
    "      \"volatile acidity\",\n",
    "      \"citric acid\",\n",
    "      \"residual sugar\",\n",
    "      \"chlorides\",\n",
    "      \"free sulfur dioxide\",\n",
    "      \"total sulfur dioxide\",\n",
    "      \"density\",\n",
    "      \"pH\",\n",
    "      \"sulphates\",\n",
    "      \"alcohol\"\n",
    "    ],\n",
    "    \"index\": [[111]],\n",
    "    \"data\": [[8.4, 0.620, 0.09, 2.20, 0.084, 11.0, 108.0, 0.99640, 3.15, 0.66, 9.8]]\n",
    "  }\n",
    "}\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "url = scoring_uri\n",
    "\n",
    "# TODO: Replace this with the primary/secondary key or AMLToken for the endpoint\n",
    "api_key = '<your endpoint API key>'\n",
    "if not api_key:\n",
    "    raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "\n",
    "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
    "# Remove this header to have the request observe the endpoint traffic rules\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'default' }\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9580d33c-b406-474e-b411-9cf88636ae55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Training Wine Model to AKS",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
