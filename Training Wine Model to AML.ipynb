{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99b6f811-6b64-44c0-9ce4-7df0370e9394",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Deploy Models from Databricks to Azure ML Endpoint\n",
    "This example notebook demonstrates how to deploy models trained in Databricks to Azure ML Managed Endpoint on Azure Machine Learning. The main goal is to be able to deploy using code only, and in a seamless manner, with only a Databricks notebook and the right configurations.\n",
    "This notebook is the part one of the series [How to deploy model trained on Databricks to Azure ML Endpoint or AKS](https://jnguyends.medium.com/in-depth-guide-deploy-models-from-databricks-to-azure-ml-2023-6d71572eb6f7). \n",
    "\n",
    "**Notebook Cluster Config:** DBR 13.0 ML / Standard DS3_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "736107d1-b418-40e4-a7c2-16e28b00ae47",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Configure Databricks to AML\n",
    "**Important:** In order to successfully let Databricks communicate with Azure ML, you will first need to **grant access** to Databricks to write and read from Azure ML. You can find how-to in the first section of the guide here: [Setup Managed Identity roles for Access Permission](https://jnguyends.medium.com/in-depth-guide-deploy-models-from-databricks-to-azure-ml-2023-6d71572eb6f7). \n",
    "\n",
    "When that's done, you can move on to the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a505a2e0-b3a1-4c79-8950-0902f1b9d890",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Install Azure Machine Learning Dependencies\n",
    "Now, you can install the following Python packages which contain integration code of AzureML with MLflow, and will help create endpoints and deploy your model. You can either use `pip install` or [install them directly on your cluster](https://learn.microsoft.com/en-us/azure/databricks/libraries/cluster-libraries#--install-a-library-on-a-cluster):\n",
    "\n",
    "- `azureml-mlflow`\n",
    "- `azure-ai-ml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8ed594a-0bf2-40d5-b25f-207644863f2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install azure-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8f05a6e-e9e6-450c-bd9e-526fff4bbae6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install azureml-mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35ee3e1f-be9f-4e4b-9be9-9b1b1f8de1ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97119c5d-86b2-40c2-8ada-ec50acddfca9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Connect MLFlow to Azure ML Server\n",
    "After that, configure your resources information to retrieve your Azure ML workspace like in the code snipped below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c14eeab5-dfe2-4838-acd2-c634c6a40d0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# TODO: Enter details of your Azure Machine Learning workspace\n",
    "subscription_id = \"<Subscription ID of your resource group>\"\n",
    "resource_group = \"<Resource group having your resources>\"\n",
    "workspace_name = \"<Your azure workspace name>\"\n",
    "\n",
    "# Retrieves your Azure ML resources with already set up Managed Identity\n",
    "ml_client = MLClient(credential=DefaultAzureCredential(),\n",
    "                        subscription_id=subscription_id, \n",
    "                        workspace_name=workspace_name,\n",
    "                        resource_group_name=resource_group)\n",
    "\n",
    "# Retrieves MLflow tracking URI of Azure ML workspace\n",
    "aml_tracking_uri = ml_client.workspaces.get(ml_client.workspace_name).mlflow_tracking_uri\n",
    "\n",
    "# Changes MLflow tracking URI to Azure ML server\n",
    "mlflow.set_tracking_uri(aml_tracking_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7666114d-0434-4aa4-bdfd-3eafbf2b517f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Train and Log Model to AML\n",
    "Now, we want to train a simple model and register it to Azure ML Model Registry. We are using the wine quality dataset to create a wine quality scoring model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "751c7582-d6ef-4f65-8eeb-4b92c9d25d51",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Load Wine Quality Dataset\n",
    "The Dataset used in this example is from http://archive.ics.uci.edu/ml/datasets/Wine+Quality. By P.Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b44e4a90-a951-42ea-b9a0-5b8ec8f9069e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import mlflow.sklearn\n",
    "\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv\", sep=\";\")\n",
    "\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train, test = train_test_split(data)\n",
    "\n",
    "# The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "train_x = train.drop([\"quality\"], axis=1)\n",
    "test_x = test.drop([\"quality\"], axis=1)\n",
    "train_y = train[[\"quality\"]]\n",
    "test_y = test[[\"quality\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1054d3c-a74a-4822-9e6d-771be5ef6196",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Train and Track ML Model Experiments\n",
    "To track MLflow experiments on Azure ML, you need to create an MLflow experiment and set the experiment. Else using MLflow will return the exception `BadRequest: Experiment ID must be a GUID.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4d6f873-4354-4bf5-84db-7e0fed26ecd3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creates and sets the experiment when using MLflow with Azure ML\n",
    "experiment_name = \"wine_quality_experiment\"\n",
    "mlflow.set_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57863234-5827-4154-8d41-888ceaf48ef7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "l1_ratio = 0.5\n",
    "artifact_path = \"model\"\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    # Keep the metadata of the run\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # Train your model\n",
    "    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "    lr.fit(train_x, train_y)\n",
    "    predicted_qualities = lr.predict(test_x)\n",
    "    mlflow.log_params({\"alpha\": alpha, \"l1_ratio\": l1_ratio})\n",
    "\n",
    "    # Infer model signature\n",
    "    signature = mlflow.models.infer_signature(model_input=test_x[:10], model_output=predicted_qualities[:10])\n",
    "\n",
    "    # Log the model to the experiment\n",
    "    mlflow.sklearn.log_model(lr, artifact_path, signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d04c043-9443-4419-8bb2-0b7f70e6b0ed",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Register the Model on Azure ML Model Registry\n",
    "Once you are satisfied with your model experimentation, you can register your best model version by using `register_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "445075ff-07fa-4845-85c9-2892e4694de9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "registered_model_name = \"wine_quality\"\n",
    "registered_model = mlflow.register_model(f\"runs:/{run_id}/{artifact_path}\", registered_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c18faf98-c5e5-4f72-9bb7-3cfac83f3cfc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Load Model for Batch Predictions\n",
    "\n",
    "You can load a model version by specifying its name and version number. Below, we load the latest version of our registered model using [mlflow.pyfunc.load_model](https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#mlflow.pyfunc.load_model) and apply it for inference on our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a9cefea-9b5e-4377-bee9-f2b2e278f55c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "model_version = registered_model.version\n",
    "model_version_uri = f\"models:/{registered_model_name}/{model_version}\"\n",
    "model_version = mlflow.pyfunc.load_model(model_version_uri)\n",
    "model_version.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "473b4597-f6bb-4bb8-a18b-5e55ee7feb79",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Serve the model with AML Endpoint\n",
    "Azure ML Endpoint are off-the-shelf solution to deployment where we don't have access to the underlying infrastructure. They are fast to deploy, require minimal configuration and maintenance whilst being less customizable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8785fe7d-1d1d-48b0-85f0-d173fe8b0880",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create the Azure ML Endpoint\n",
    "In order to create an Azure ML Managed Endpoint, we need as input a configuration file in json format with a few parameters.\n",
    "- `auth_mode`: Determines authentication mode for the endpoint. Can be `\"key\"`, `\"anonymous\"` or `\"aad\"`.\n",
    "- `identity / type`: Specifies the type of identity assigned to the endpoint. Can be `\"none\"`, `\"system_assigned\"` or `\"user_assigned\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ff54f61-2f2e-4eff-a725-3058ff9a1d27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Write the endpoint configuration file \n",
    "endpoint_config_path = \"endpoint_config.json\"\n",
    "endpoint_config = {\n",
    "    \"auth_mode\": \"key\",\n",
    "    \"identity\": {\n",
    "        \"type\": \"system_assigned\"\n",
    "    }\n",
    "}\n",
    "with open(endpoint_config_path, \"w\") as outfile:\n",
    "    outfile.write(json.dumps(endpoint_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f66c06c-162e-42d1-91f4-5f3384811ee2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Since we want to deploy on Azure ML, we retrieve the deployment_client associated to our workspace using Azure ML tracking URI. Then, we create the endpoint using the configuration file created above and give it a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25a861e6-bfea-47b4-8c20-ebccd6fad560",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "# Create the deployment client linked to Azure ML workspace\n",
    "deployment_client = get_deploy_client(aml_tracking_uri)  \n",
    "\n",
    "# Create a AML managed endpoint \n",
    "endpoint_name = \"wine-endpoint-test\"\n",
    "endpoint = deployment_client.create_endpoint(\n",
    "    name=endpoint_name,\n",
    "    config={\"endpoint-config-file\": endpoint_config_path}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaff6e13-16a3-4159-940a-be22c41f0740",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Deploy the Model on the Endpoint and Assign Traffic\n",
    "When endpoint are created, they are initially empty and waiting for deployment to be made on it. An endpoint can host multiple deployments.\n",
    "Let's create a first deployment. First, we specify the compute resources we want to allocate to that deployment in a configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa9a5928-f2fc-4e4e-b899-205f1dd56c38",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "blue_deployment_name = \"default\"\n",
    "deploy_config = {\n",
    "    \"instance_type\": \"Standard_DS2_v2\",\n",
    "    \"instance_count\": 1,\n",
    "}\n",
    "deployment_config_path = \"deployment_config.json\"\n",
    "with open(deployment_config_path, \"w\") as outfile:\n",
    "    outfile.write(json.dumps(deploy_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d8ee154-e553-4601-bc0d-4be6046edeab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Then, we can use the `deployment_client` to create a deployment on the endpoint we created. Inputs are our model name and version we logged in the Model Registry and the configuration file we've just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04d04198-21b9-4b6e-9843-21984f16e39c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = registered_model_name\n",
    "version = registered_model.version\n",
    "\n",
    "blue_deployment = deployment_client.create_deployment(\n",
    "    name=blue_deployment_name,\n",
    "    endpoint=endpoint_name,\n",
    "    model_uri=f\"models:/{model_name}/{version}\",\n",
    "    config={\"deploy-config-file\": deployment_config_path},\n",
    ")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05d591ea-55d5-46b1-968d-76528da4ebf8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The deployment will take a few minutes to roll out. Before we can call our model through endpoint requests, we need to update the traffic percent our deployment gets by the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2291dbd-a116-481c-9127-f5622dcd83f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "traffic_config = {\"traffic\": {deployment_name: 100}}\n",
    "traffic_config_path = \"traffic_config.json\"\n",
    "with open(traffic_config_path, \"w\") as outfile:\n",
    "    outfile.write(json.dumps(traffic_config))\n",
    "\n",
    "deployment_client.update_endpoint(\n",
    "    endpoint=endpoint_name,\n",
    "    config={\"endpoint-config-file\": traffic_config_path},\n",
    ")  \n",
    "\n",
    "scoring_uri = deployment_client.get_endpoint(endpoint=endpoint_name)[\"properties\"][\"scoringUri\"]\n",
    "print(scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8db25744-23e0-4451-84ad-bff0df593627",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "After that, you are done and you can test out your served model! \n",
    "\n",
    "You can either use Azure ML UI or make requests on Postman / Databricks. Here's a request example below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6ed846b-1bf0-49a1-86e5-be6dad082a00",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Query AML Endpoint with requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d4262e3-57e0-441f-8a8c-642964909e43",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "data =  {\n",
    "  \"input_data\": {\n",
    "    \"columns\": [\n",
    "      \"fixed acidity\",\n",
    "      \"volatile acidity\",\n",
    "      \"citric acid\",\n",
    "      \"residual sugar\",\n",
    "      \"chlorides\",\n",
    "      \"free sulfur dioxide\",\n",
    "      \"total sulfur dioxide\",\n",
    "      \"density\",\n",
    "      \"pH\",\n",
    "      \"sulphates\",\n",
    "      \"alcohol\"\n",
    "    ],\n",
    "    \"index\": [[111]],\n",
    "    \"data\": [[8.4, 0.620, 0.09, 2.20, 0.084, 11.0, 108.0, 0.99640, 3.15, 0.66, 9.8]]\n",
    "  }\n",
    "}\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "url = scoring_uri\n",
    "\n",
    "# TODO: Replace this with the primary/secondary key or AMLToken for the endpoint\n",
    "api_key = '<your endpoint API key>'\n",
    "if not api_key:\n",
    "    raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "\n",
    "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
    "# Remove this header to have the request observe the endpoint traffic rules\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'default' }\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a684367-a2c4-44ef-8ac7-85431d379bbb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Training Wine Model to AML",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
